{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motrainer\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.config.set(scheduler='synchronous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\"../example/example1_data.zarr/\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split per gridcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motrainer.is_splitable(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags = motrainer.dataset_split(ds, \"space\")\n",
    "bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(ds):\n",
    "    return ds.to_dask_dataframe()\n",
    "\n",
    "def chunk(ds, chunks):\n",
    "    return ds.chunk(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splir\n",
    "train_test_bags = bags.map(\n",
    "    motrainer.train_test_split, split={\"time\": np.datetime64(\"2016-01-01\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bags = train_test_bags.pluck(0).map(chunk, {\"space\": 500}).map(to_dataframe)\n",
    "test_bags = train_test_bags.pluck(1).map(chunk, {\"space\": 500}).map(to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup grid search\n",
    "# use the estimator definition and pipeline objects in sklearn\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "regSVR = make_pipeline(MinMaxScaler(), SVR())\n",
    "kernel = [\"poly\", \"rbf\", \"sigmoid\"]\n",
    "C = [1, 0.1]\n",
    "gamma = [\"scale\"]\n",
    "grid = dict(svr__kernel=kernel, svr__C=C, svr__gamma=gamma)\n",
    "cv = RepeatedKFold(n_splits=4, n_repeats=2, random_state=1)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=regSVR,\n",
    "    param_grid=grid,\n",
    "    cv=cv,\n",
    "    scoring=[\"r2\", \"neg_mean_squared_error\"],\n",
    "    refit=\"r2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(df, grid_search, input_list, output_list):\n",
    "    \"\"\"Customized Optimization Function\n",
    "    \"\"\"\n",
    "    df = df.dropna()\n",
    "    grid_result = grid_search.fit(df[input_list], df[output_list])\n",
    "    return grid_result\n",
    "\n",
    "\n",
    "input_list = [\"BIOMA1\", \"BIOMA1\", \"TG1\", \"TG2\", \"TG3\"]\n",
    "output_list = [\"slop\"]\n",
    "optimazed_estimators = train_bags.map(\n",
    "    optimize, grid_search=grid_search, input_list=input_list, output_list=output_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimazed_estimators_realized = optimazed_estimators.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced by \"modelstore\"\n",
    "import pickle\n",
    "\n",
    "for model, id in zip(optimazed_estimators_realized, range(len(optimazed_estimators_realized))):\n",
    "    name_model = f\"model{id}.pickle\"\n",
    "    with open(name_model, \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models back\n",
    "list_model = []\n",
    "for id in range(5): \n",
    "    with open(f\"model{id}.pickle\", \"rb\") as f:\n",
    "        list_model.append(pickle.load(f))\n",
    "list_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error , r2_score,  mean_absolute_error\n",
    "\n",
    "# This for need to be coverted to a user defined \n",
    "list_metrics = []\n",
    "for model, test_data in zip(list_model, test_bags.compute()):\n",
    "    test_data = test_data.dropna()\n",
    "    X_test = test_data[input_list]\n",
    "    Y_test = test_data[output_list]\n",
    "    Y_eval = model.predict(X_test)\n",
    "\n",
    "    metrics = {\"MSE_SVR\": mean_squared_error(Y_test,Y_eval),\n",
    "               \"MAE_SVR\": mean_absolute_error(Y_test,Y_eval),\n",
    "               \"R_2\":r2_score(Y_test,Y_eval)}\n",
    "    list_metrics.append(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motrainer-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
