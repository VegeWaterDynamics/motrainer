{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Modelstore with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a toy model with keras (inspired from the [introduction to deep learning lesson](https://carpentries-incubator.github.io/deep-learning-intro/2-keras.html))\n",
    "\n",
    "This model is used to classify penguins in to three different species based on characteristic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load and prep the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "penguins = sns.load_dataset('penguins')\n",
    "penguins_filtered = penguins.drop(columns=['island', 'sex'])\n",
    "penguins_filtered = penguins_filtered.dropna()\n",
    "penguins_features = penguins_filtered.drop(columns=['species'])\n",
    "target = pd.get_dummies(penguins_filtered['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(penguins_features, target,test_size=0.2, random_state=0, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=X_train.shape[1])\n",
    "hidden_layer = keras.layers.Dense(10, activation=\"relu\")(inputs)\n",
    "output_layer = keras.layers.Dense(3, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compile and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 979.7580\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 833.3919\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 782.9046\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 728.6353\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 684.7715\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 643.6425\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 601.0027\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 557.9034\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 516.2161\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 475.0002\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 433.2507\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 388.9162\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 346.0887\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 306.4019\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 263.1983\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 219.5359\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 177.6934\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 134.2565\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 92.8082\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 50.2980\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 14.5926\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 13.1579\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.4253\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 10.2679\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.9348\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.2231\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.0682\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.0089\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7049\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.5794\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.3940\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.4728\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 6.4854\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8553\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0883\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.0704\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.1899\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.9001\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 6.0312\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2783\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.1139\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.4940\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.6093\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8550\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3772\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9738\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.7671\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9870\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7020\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2723\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.2627\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.2905\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.4330\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7857\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.4495\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3245\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6591\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3611\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.6999\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.6920\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.2173\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.1632\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.2378\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4561\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2746\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3727\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.3497\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7535\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.6356\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5581\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1176\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0023\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8083\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7756\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6961\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2372\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0262\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8468\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2139\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9202\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4735\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2084\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3403\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3274\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5293\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9307\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4786\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9536\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.7081\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6820\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7477\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7555\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6255\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9330\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1114\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2857\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1836\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7861\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6261\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6487\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy())\n",
    "history = model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Save the model using modelstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install modelstore using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install modelstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelstore import ModelStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create local storage for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏦  Creating store in: modelstore\n"
     ]
    }
   ],
   "source": [
    "path = 'modelstore'\n",
    "print(f\"🏦  Creating store in: {path}\")\n",
    "model_store = ModelStore.from_file_system(root_directory=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model in model store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 15:44:57,423 | absl | WARNING | Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpukjb0zsp/model/assets\n",
      "2023-09-27 15:44:57,523 | tensorflow | INFO | Assets written to: /tmp/tmpukjb0zsp/model/assets\n"
     ]
    }
   ],
   "source": [
    "domain = \"penguin-classification\"\n",
    "model_id = \"penguin_toy_model_1\"\n",
    "meta_data = model_store.upload(domain=domain, model_id=model_id model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'domain': 'penguin-classification',\n",
       "  'model_id': 'b490b1ff-01ab-4a34-9ae5-2ea622c93faf',\n",
       "  'model_type': {'library': 'tensorflow',\n",
       "   'type': 'Functional',\n",
       "   'models': None},\n",
       "  'parameters': {'name': 'Adam',\n",
       "   'weight_decay': None,\n",
       "   'clipnorm': None,\n",
       "   'global_clipnorm': None,\n",
       "   'clipvalue': None,\n",
       "   'use_ema': False,\n",
       "   'ema_momentum': 0.99,\n",
       "   'ema_overwrite_frequency': None,\n",
       "   'jit_compile': False,\n",
       "   'is_legacy_optimizer': False,\n",
       "   'learning_rate': 0.0010000000474974513,\n",
       "   'beta_1': 0.9,\n",
       "   'beta_2': 0.999,\n",
       "   'epsilon': 1e-07,\n",
       "   'amsgrad': False},\n",
       "  'data': None},\n",
       " 'storage': {'type': 'file_system',\n",
       "  'root': '/mnt/c/Users/PranavChandramouli/OneDrive - Netherlands eScience Center/Projects/Global_Vegetation/motrainer/example/modelstore_example/modelstore',\n",
       "  'path': '/mnt/c/Users/PranavChandramouli/OneDrive - Netherlands eScience Center/Projects/Global_Vegetation/motrainer/example/modelstore_example/modelstore/operatorai-model-store/penguin-classification/2023.09.27-15.44.57/b490b1ff-01ab-4a34-9ae5-2ea622c93faf/artifacts.tar.gz',\n",
       "  'bucket': None,\n",
       "  'prefix': None,\n",
       "  'container': None},\n",
       " 'modelstore': '0.0.79',\n",
       " 'code': {'runtime': 'python:3.11.5',\n",
       "  'user': 'cpranav93',\n",
       "  'created': '2023/09/27/15:44:57',\n",
       "  'dependencies': {'h5py': '3.9.0',\n",
       "   'numpy': '1.23.5',\n",
       "   'scipy': '1.11.2',\n",
       "   'tensorflow': '2.12.1',\n",
       "   'pip': '23.2.1',\n",
       "   'setuptools': '68.2.2',\n",
       "   'pandas': '2.0.3'},\n",
       "  'git': {'repository': 'motrainer',\n",
       "   'sha': '5bc85d03cdcd4433062881fd990a609b93270389',\n",
       "   'local_changes': True,\n",
       "   'branch': 'save_models'}},\n",
       " 'extra': None}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motrainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
